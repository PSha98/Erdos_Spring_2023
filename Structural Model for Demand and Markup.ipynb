{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b15737",
   "metadata": {},
   "source": [
    "This file compute demand parameter using IV regression rather than OLS. Because OLS is biased. \n",
    "\n",
    "\n",
    "Takeaway from demand parameters: \n",
    "\n",
    "Consumers are willing to pay 2 dollars more to upgrate to Entire home from private room.\n",
    "\n",
    "Consumers are willing to pay 71 dolars more to book a propertity mangaged by super hosts.\n",
    "\n",
    "The average profit margin for the host is 8% (rate of return) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44a5b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate market demand, price elasticites, markup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3654cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LA\\March\\listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1772048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.720346127144699"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data cleaning. Price data has $ sign. The following code extracts the number\n",
    "df['price'] = df['price'].replace({r'\\$':''},regex = True).replace({r',':''},regex = True).astype('float')\n",
    "df.price\n",
    "# delete the listings which are more expensive than $800\n",
    "df1=df[df.price<800]\n",
    "df1.reviews_per_month.isna().sum()/len(df1)\n",
    "\n",
    "#get the subset of the data without missing \n",
    "\n",
    "df2= df1[~df1.beds.isna()&~df1.reviews_per_month.isna()&~df1.review_scores_accuracy.isna()&~df1.review_scores_checkin.isna()\n",
    "         &~df1.review_scores_communication.isna()&~df1.review_scores_location.isna()&~df1.review_scores_value.isna()]\n",
    "len(df2)/len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c36e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for top 30 neighbourhood market # this can be replaced by hotspot\n",
    "\n",
    "listtop30 = df2.neighbourhood_cleansed.value_counts().head(30).index.tolist()\n",
    "df3=df2[df2[\"neighbourhood_cleansed\"].isin(listtop30)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e4666e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.copy() \n",
    "# create market share from reviews\n",
    "df3.loc[:,'share'] =df3['reviews_per_month']/(df3.groupby('neighbourhood_cleansed')['reviews_per_month'].transform('sum')*3)\n",
    "\n",
    "# 2/3 is arbitrary, won't affect result much, create mean valuation of the listing\n",
    "df3['mean_value'] =np.log(df3['share']/(2/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01a756",
   "metadata": {},
   "source": [
    "The following block run simple OLS.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "02792458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             mean_value   R-squared:                       0.210\n",
      "Model:                            OLS   Adj. R-squared:                  0.209\n",
      "Method:                 Least Squares   F-statistic:                     190.7\n",
      "Date:                Mon, 29 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        21:57:27   Log-Likelihood:                -25831.\n",
      "No. Observations:               15052   AIC:                         5.171e+04\n",
      "Df Residuals:                   15030   BIC:                         5.187e+04\n",
      "Df Model:                          21                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                   -7.5179      0.126    -59.627      0.000      -7.765      -7.271\n",
      "price                   -0.0008      0.000     -6.861      0.000      -0.001      -0.001\n",
      "beds                     0.1096      0.010     10.866      0.000       0.090       0.129\n",
      "license                  0.2876      0.026     11.259      0.000       0.238       0.338\n",
      "Entire home/apt         -1.5472      0.058    -26.641      0.000      -1.661      -1.433\n",
      "Hotel room              -2.4891      0.154    -16.116      0.000      -2.792      -2.186\n",
      "Private room            -1.6539      0.059    -28.112      0.000      -1.769      -1.539\n",
      "Shared room             -1.8278      0.113    -16.222      0.000      -2.049      -1.607\n",
      "host_is_superhost        0.4162      0.025     16.826      0.000       0.368       0.465\n",
      "review_scores_rating    -0.0039      0.024     -0.159      0.874      -0.052       0.044\n",
      "amenities                0.0053      0.000     14.791      0.000       0.005       0.006\n",
      "amenities                0.5325      0.106      5.020      0.000       0.325       0.740\n",
      "amenities               -0.1546      0.046     -3.366      0.001      -0.245      -0.065\n",
      "amenities               -0.6828      0.041    -16.834      0.000      -0.762      -0.603\n",
      "amenities                0.1653      0.034      4.883      0.000       0.099       0.232\n",
      "amenities                0.0896      0.023      3.867      0.000       0.044       0.135\n",
      "amenities                0.2989      0.026     11.440      0.000       0.248       0.350\n",
      "amenities               -0.2906      0.039     -7.440      0.000      -0.367      -0.214\n",
      "amenities               -0.0269      0.036     -0.741      0.459      -0.098       0.044\n",
      "amenities                0.3452      0.034     10.158      0.000       0.279       0.412\n",
      "amenities                0.2842      0.032      8.873      0.000       0.221       0.347\n",
      "amenities               -0.1603      0.032     -4.937      0.000      -0.224      -0.097\n",
      "amenities                0.1527      0.031      4.862      0.000       0.091       0.214\n",
      "==============================================================================\n",
      "Omnibus:                      243.676   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              250.097\n",
      "Skew:                          -0.304   Prob(JB):                     4.92e-55\n",
      "Kurtosis:                       2.830   Cond. No.                     7.71e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.43e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# for indirect utility\n",
    "Y=df3.mean_value\n",
    "#with amenties\n",
    "\n",
    "\n",
    "license_dummy=1*(~df3.license.isna()) \n",
    "# Fill NAN by \"missing\" string\n",
    "df3[['host_response_time']] = df3[['host_response_time']].fillna('Missing_response')\n",
    "host_response_dummy=pd.get_dummies(df3.host_response_time)\n",
    "#room_type dummy\n",
    "room_type_dummy=pd.get_dummies(df3.room_type)\n",
    "super_host_dummy =1*(df3.host_is_superhost==\"t\")\n",
    "\n",
    "amentity_count=df3.amenities.str.split().str.len()\n",
    "wifi = 1*df3.amenities.str.lower().str.contains('wifi', regex=True) \n",
    "washer = 1*df3.amenities.str.lower().str.contains('washer', regex=True) \n",
    "dryer = 1*df3.amenities.str.lower().str.replace(\"hair dryer\", \" \").str.lower().str.contains('dryer', regex=True)\n",
    "hair_dryer = 1*df3.amenities.str.lower().str.contains('hair dryer', regex=True) \n",
    "free_parking = 1*df3.amenities.str.lower().str.contains('free parking', regex=True) \n",
    "AC = 1*df3.amenities.str.lower().str.contains('air conditioning', regex=True) \n",
    "TV= 1*df3.amenities.str.lower().str.contains('tv', regex=True) \n",
    "hottub = 1*df3.amenities.str.lower().str.contains('hot tub', regex=True) \n",
    "coffee = 1*df3.amenities.str.lower().str.contains('coffee', regex=True) \n",
    "microwave = 1*df3.amenities.str.lower().str.contains('microwave', regex=True) \n",
    "pool = 1*df3.amenities.str.lower().str.contains('pool', regex=True) \n",
    "shampoo = 1*df3.amenities.str.lower().str.contains('shampoo', regex=True) \n",
    "\n",
    "X=pd.concat([df3.price,df3.beds,license_dummy,\n",
    "             room_type_dummy,super_host_dummy,df3.review_scores_rating,amentity_count,wifi,\n",
    "             washer,dryer,hair_dryer,free_parking,AC,TV,hottub,coffee,microwave,pool,shampoo],axis=1)\n",
    "             \n",
    "             #df2.host_response_rate,df2.host_acceptance_rate,df2.host_is_superhost,df2.room_type],axis=1)\n",
    "X=sm.add_constant(X)\n",
    "mod = sm.OLS(Y,X)\n",
    "est = mod.fit()\n",
    "\n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e254ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-141.69389892182798\n",
      "-552.5969886000523\n"
     ]
    }
   ],
   "source": [
    "print((est.params['Entire home/apt']-est.params['Private room'])/est.params['price'])\n",
    "print(est.params['host_is_superhost']/est.params['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce3b7d",
   "metadata": {},
   "source": [
    "Consumers are willing to pay 142 dollars more to upgrate to Entire home from private room.\n",
    "\n",
    "Consumers are willing to pay 552 dolars more to book a propertity mangaged by super hosts.\n",
    "\n",
    "This doesn't really make sense.\n",
    "\n",
    "Because of price endogeneity here, I use instrument variable (IV) to get a correct price coeffcient. \n",
    "\n",
    "The following code computes IV results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4168e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV2SLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>mean_value</td>    <th>  R-squared:         </th> <td> -46.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>IV2SLS</td>      <th>  Adj. R-squared:    </th> <td> -46.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>Two Stage</td>    <th>  F-statistic:       </th> <td>     nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                    <td>Least Squares</td>  <th>  Prob (F-statistic):</th>  <td>   nan</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 29 May 2023</td> <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:58:15</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15052</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15030</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    21</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price</th>                <td>   -0.1038</td> <td>    0.016</td> <td>   -6.577</td> <td> 0.000</td> <td>   -0.135</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds</th>                 <td>    4.2210</td> <td>    0.634</td> <td>    6.662</td> <td> 0.000</td> <td>    2.979</td> <td>    5.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>license</th>              <td>    4.5189</td> <td>    0.677</td> <td>    6.679</td> <td> 0.000</td> <td>    3.193</td> <td>    5.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Entire home/apt</th>      <td>   -8.5537</td> <td>    1.171</td> <td>   -7.305</td> <td> 0.000</td> <td>  -10.849</td> <td>   -6.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Hotel room</th>           <td>  -10.4800</td> <td>    1.825</td> <td>   -5.742</td> <td> 0.000</td> <td>  -14.057</td> <td>   -6.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Private room</th>         <td>  -15.9352</td> <td>    1.561</td> <td>  -10.207</td> <td> 0.000</td> <td>  -18.995</td> <td>  -12.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Shared room</th>          <td>  -20.2491</td> <td>    2.235</td> <td>   -9.061</td> <td> 0.000</td> <td>  -24.630</td> <td>  -15.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_is_superhost</th>    <td>    0.1972</td> <td>    0.194</td> <td>    1.017</td> <td> 0.309</td> <td>   -0.183</td> <td>    0.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_rating</th> <td>    0.9700</td> <td>    0.240</td> <td>    4.040</td> <td> 0.000</td> <td>    0.499</td> <td>    1.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.0538</td> <td>    0.008</td> <td>    6.795</td> <td> 0.000</td> <td>    0.038</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.7586</td> <td>    0.820</td> <td>    0.926</td> <td> 0.355</td> <td>   -0.848</td> <td>    2.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    1.5064</td> <td>    0.436</td> <td>    3.454</td> <td> 0.001</td> <td>    0.652</td> <td>    2.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>   -1.0006</td> <td>    0.317</td> <td>   -3.157</td> <td> 0.002</td> <td>   -1.622</td> <td>   -0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.0909</td> <td>    0.262</td> <td>    0.347</td> <td> 0.728</td> <td>   -0.422</td> <td>    0.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    1.1493</td> <td>    0.241</td> <td>    4.761</td> <td> 0.000</td> <td>    0.676</td> <td>    1.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    2.1472</td> <td>    0.347</td> <td>    6.183</td> <td> 0.000</td> <td>    1.467</td> <td>    2.828</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.3073</td> <td>    0.315</td> <td>    0.975</td> <td> 0.330</td> <td>   -0.310</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    2.1924</td> <td>    0.440</td> <td>    4.982</td> <td> 0.000</td> <td>    1.330</td> <td>    3.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.7031</td> <td>    0.268</td> <td>    2.623</td> <td> 0.009</td> <td>    0.178</td> <td>    1.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>   -3.4875</td> <td>    0.628</td> <td>   -5.557</td> <td> 0.000</td> <td>   -4.718</td> <td>   -2.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.3017</td> <td>    0.261</td> <td>    1.158</td> <td> 0.247</td> <td>   -0.209</td> <td>    0.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>amenities</th>            <td>    0.9005</td> <td>    0.268</td> <td>    3.359</td> <td> 0.001</td> <td>    0.375</td> <td>    1.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>5036.980</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>22806.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.579</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 8.137</td>  <th>  Cond. No.          </th> <td>7.03e+03</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          IV2SLS Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:             mean_value   R-squared:                     -46.063\n",
       "Model:                         IV2SLS   Adj. R-squared:                -46.129\n",
       "Method:                     Two Stage   F-statistic:                       nan\n",
       "                        Least Squares   Prob (F-statistic):                nan\n",
       "Date:                Mon, 29 May 2023                                         \n",
       "Time:                        21:58:15                                         \n",
       "No. Observations:               15052                                         \n",
       "Df Residuals:                   15030                                         \n",
       "Df Model:                          21                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "price                   -0.1038      0.016     -6.577      0.000      -0.135      -0.073\n",
       "beds                     4.2210      0.634      6.662      0.000       2.979       5.463\n",
       "license                  4.5189      0.677      6.679      0.000       3.193       5.845\n",
       "Entire home/apt         -8.5537      1.171     -7.305      0.000     -10.849      -6.259\n",
       "Hotel room             -10.4800      1.825     -5.742      0.000     -14.057      -6.903\n",
       "Private room           -15.9352      1.561    -10.207      0.000     -18.995     -12.875\n",
       "Shared room            -20.2491      2.235     -9.061      0.000     -24.630     -15.869\n",
       "host_is_superhost        0.1972      0.194      1.017      0.309      -0.183       0.577\n",
       "review_scores_rating     0.9700      0.240      4.040      0.000       0.499       1.441\n",
       "amenities                0.0538      0.008      6.795      0.000       0.038       0.069\n",
       "amenities                0.7586      0.820      0.926      0.355      -0.848       2.365\n",
       "amenities                1.5064      0.436      3.454      0.001       0.652       2.361\n",
       "amenities               -1.0006      0.317     -3.157      0.002      -1.622      -0.379\n",
       "amenities                0.0909      0.262      0.347      0.728      -0.422       0.604\n",
       "amenities                1.1493      0.241      4.761      0.000       0.676       1.622\n",
       "amenities                2.1472      0.347      6.183      0.000       1.467       2.828\n",
       "amenities                0.3073      0.315      0.975      0.330      -0.310       0.925\n",
       "amenities                2.1924      0.440      4.982      0.000       1.330       3.055\n",
       "amenities                0.7031      0.268      2.623      0.009       0.178       1.228\n",
       "amenities               -3.4875      0.628     -5.557      0.000      -4.718      -2.257\n",
       "amenities                0.3017      0.261      1.158      0.247      -0.209       0.812\n",
       "amenities                0.9005      0.268      3.359      0.001       0.375       1.426\n",
       "==============================================================================\n",
       "Omnibus:                     5036.980   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22806.090\n",
       "Skew:                           1.579   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.137   Cond. No.                     7.03e+03\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "# instrument for price endogeneity\n",
    "df3.loc[:,'IV'] = df3.groupby(['neighbourhood_cleansed'])['id'].transform('count')\n",
    "\n",
    "Y=df3.mean_value\n",
    "X=pd.concat([df3.price,df3.beds,license_dummy,\n",
    "             room_type_dummy,super_host_dummy,df3.review_scores_rating,amentity_count,wifi,\n",
    "             washer,dryer,hair_dryer,free_parking,AC,TV,hottub,coffee,microwave,pool,shampoo],axis=1)\n",
    "exog_constant=X\n",
    "#sm.add_constant(X)\n",
    "endog = Y\n",
    "instr_constant = sm.add_constant(pd.concat([df3.IV,df3.beds,license_dummy,\n",
    "             room_type_dummy,super_host_dummy,df3.review_scores_rating,amentity_count,wifi,\n",
    "             washer,dryer,hair_dryer,free_parking,AC,TV,hottub,coffee,microwave,pool,shampoo],axis=1))\n",
    "endog_results = IV2SLS(endog, exog_constant, instrument = instr_constant).fit()\n",
    "endog_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a4d6ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.9002046952246943\n",
      "-71.11866549570298\n"
     ]
    }
   ],
   "source": [
    "print(endog_results.params['host_is_superhost']/endog_results.params['price'])\n",
    "print((endog_results.params['Entire home/apt']-endog_results.params['Private room'])/endog_results.params['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2436119",
   "metadata": {},
   "source": [
    "Consumers are willing to pay 71 dollars more to upgrate to Entire home from private room.\n",
    "\n",
    "Consumers are willing to pay 2 dolars more to book a propertity mangaged by super hosts.\n",
    "\n",
    "The following code computes markup based on IV regression results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f5195894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#markup \n",
    "markup =[]\n",
    "df3 = df3.copy()\n",
    "# number of the markets (hotspots)\n",
    "M = df3['neighbourhood_cleansed'].nunique()\n",
    "Group_market = df3.groupby('neighbourhood_cleansed')\n",
    "#elaciticies\n",
    "ela = [] \n",
    "for num, i in enumerate(df3['neighbourhood_cleansed'].unique()):\n",
    "    submarket = Group_market.get_group(i)\n",
    "    share_m = np.array(submarket.share)\n",
    "    dsdp_m =  endog_results.params['price']*(np.diag(share_m)-np.outer(share_m,share_m)) #price derivatives\n",
    "    \n",
    "    #ela\n",
    "    ela_m =dsdp_m*np.array(np.array(submarket.price).reshape(-1, 1) )/np.array(submarket.share)# that's how i compute elasticities  \n",
    "    ela.append(ela_m)\n",
    "    \n",
    "    # markup\n",
    "    host_id = submarket.host_id.to_numpy()\n",
    "    T = host_id [:, np.newaxis] == host_id \n",
    "    markup.append(-np.dot(np.linalg.inv(T*dsdp_m),share_m))\n",
    "     # assign markup back to dataFrame df3\n",
    "    df3.loc[df3['neighbourhood_cleansed'] == i, 'markup'] = markup[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60572ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a quick check \n",
    "#df3['neighbourhood_cleansed'].unique()\n",
    "#i =\"Rowland Heights\"\n",
    "#submarket = Group_market.get_group(i)\n",
    "#share_m = np.array(submarket.share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e78528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average markup per listing is $ 9.66\n",
      "average rate of return is 0.08\n"
     ]
    }
   ],
   "source": [
    "df3.markup.head() #markup for the first 10 listing in the first market\n",
    "\n",
    "#profit margain in percentage\n",
    "\n",
    "df3['margin_perc'] = df3.markup/df3.price\n",
    "print(\"average markup per listing is $\",str(round(df3.markup.mean(),2)) )\n",
    "print(\"average rate of return is\",str(round(df3.margin_perc.mean(),2)))\n",
    "df3['mc'] = df3['price']-df3['markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f068c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.diag(ela[0]) # own ric elaciticites in the first market "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57804970",
   "metadata": {},
   "source": [
    "The following code tries lasso. No siginificant gain in accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd3a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.001}\n",
      "Best Score: 0.20292170807155507\n"
     ]
    }
   ],
   "source": [
    "# Lasso \n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Define parameter grid\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=777)\n",
    "param_grid = {'alpha': [0.0001,0.001, 0.01, 0.1, 1, 10]}\n",
    " \n",
    "# Perform grid search with cross-validation\n",
    "lasso_cv = GridSearchCV(Lasso(), param_grid, cv=5)\n",
    "lasso_cv.fit(X_train, Y_train)\n",
    " \n",
    "# Print best parameter values and score\n",
    "print(\"Best Parameters:\", lasso_cv.best_params_)\n",
    "print(\"Best Score:\", lasso_cv.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d842bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01189117, 0.01068273, 0.00935316, 0.0062696 , 0.00783801,\n",
       "        0.01254196]),\n",
       " 'std_fit_time': array([0.0060644 , 0.00640214, 0.00763692, 0.00767866, 0.00504703,\n",
       "        0.00592282]),\n",
       " 'mean_score_time': array([0.0031219 , 0.00190339, 0.0031249 , 0.00624113, 0.00558414,\n",
       "        0.00160294]),\n",
       " 'std_score_time': array([0.0062438 , 0.00380678, 0.00624981, 0.0076438 , 0.00233563,\n",
       "        0.0020585 ]),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.0001},\n",
       "  {'alpha': 0.001},\n",
       "  {'alpha': 0.01},\n",
       "  {'alpha': 0.1},\n",
       "  {'alpha': 1},\n",
       "  {'alpha': 10}],\n",
       " 'split0_test_score': array([0.22275146, 0.22260922, 0.21416753, 0.11606427, 0.09674889,\n",
       "        0.06320693]),\n",
       " 'split1_test_score': array([0.21070995, 0.21105985, 0.20521431, 0.09115998, 0.07329301,\n",
       "        0.05708773]),\n",
       " 'split2_test_score': array([0.18417126, 0.18422974, 0.18279918, 0.10420658, 0.08379628,\n",
       "        0.05974867]),\n",
       " 'split3_test_score': array([0.18264027, 0.18266771, 0.17809617, 0.09854426, 0.07861373,\n",
       "        0.05726002]),\n",
       " 'split4_test_score': array([0.2139131 , 0.21404202, 0.2110954 , 0.10293107, 0.08297254,\n",
       "        0.06012592]),\n",
       " 'mean_test_score': array([0.20283721, 0.20292171, 0.19827452, 0.10258123, 0.08308489,\n",
       "        0.05948585]),\n",
       " 'std_test_score': array([0.01635583, 0.016353  , 0.01491158, 0.00814001, 0.00778583,\n",
       "        0.00223743]),\n",
       " 'rank_test_score': array([2, 1, 3, 4, 5, 6])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " lasso_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33917ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8157141626183637\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.0001)\n",
    "lasso.fit(X_train, Y_train)\n",
    "Y_pred = lasso.predict(X_test)\n",
    "MSE = ((Y_pred-Y_test)**2).mean()\n",
    "print(MSE)\n",
    "coefs = lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d0257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8155887528108074\n"
     ]
    }
   ],
   "source": [
    "#OLS \n",
    "\n",
    "mod = sm.OLS(Y_train,X_train)\n",
    "est = mod.fit()\n",
    "Y_pred_OLS=est.predict(X_test)\n",
    "MSE_OLS = ((Y_pred_OLS-Y_test)**2).mean()\n",
    "print(MSE_OLS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
